{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aa81a7a",
   "metadata": {},
   "source": [
    "# Un notebook Jupyter pour tester des modèles pré-entraînés pour l'analyse de sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571d0b43",
   "metadata": {},
   "source": [
    "## Importation des Bibliothèques Nécessaires\n",
    "Importer les bibliothèques nécessaires, notamment `transformers`, `sklearn`, `numpy`, et `mlflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7678e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d035d7",
   "metadata": {},
   "source": [
    "## Chargement des Données\n",
    "Charger les données textuelles et les labels associés pour l'analyse de sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc727be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "# Exemple : Charger un fichier CSV contenant des tweets et leurs sentiments associés\n",
    "data = pd.read_csv(\"tweet_data_final.csv\")\n",
    "data.info()\n",
    "data.head()\n",
    "\n",
    "# Diviser les données en texte et labels\n",
    "texts = data[\"text_cleaned_tokens_stem\"]\n",
    "labels = data[\"target\"]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(texts, labels, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40188fe2",
   "metadata": {},
   "source": [
    "## Définition de la Fonction `evaluate_model`\n",
    "Définir une fonction `evaluate_model` qui charge un modèle pré-entraîné, effectue la tokenisation, divise les données en ensembles d'entraînement et de validation, et calcule les métriques de performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219b45a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir une fonction pour évaluer un modèle pré-entraîné\n",
    "def evaluate_model(model_name, X_train, X_val, y_train, y_val):\n",
    "    \"\"\"\n",
    "    Évalue un modèle pré-entraîné pour l'analyse de sentiments.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Nom du modèle pré-entraîné à charger.\n",
    "        X_train (list): Ensemble d'entraînement des textes.\n",
    "        X_val (list): Ensemble de validation des textes.\n",
    "        y_train (list): Labels associés à l'ensemble d'entraînement.\n",
    "        y_val (list): Labels associés à l'ensemble de validation.\n",
    "    \"\"\"\n",
    "    # Initialiser MLflow\n",
    "    if mlflow.active_run() is not None:\n",
    "        mlflow.end_run()\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Charger le tokenizer et le modèle\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        \n",
    "        # Créer un pipeline pour la classification\n",
    "        sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "        \n",
    "        # Prédictions sur l'ensemble de validation\n",
    "        predictions = sentiment_pipeline(X_val.tolist())\n",
    "        predicted_labels = [1 if pred[\"label\"] == \"POSITIVE\" else 0 for pred in predictions]\n",
    "        \n",
    "        # Calculer les métriques\n",
    "        accuracy = accuracy_score(y_val, predicted_labels)\n",
    "        report = classification_report(y_val, predicted_labels, target_names=[\"NEGATIVE\", \"POSITIVE\"])\n",
    "        \n",
    "        # Enregistrer les métriques dans MLflow\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_text(report, \"classification_report.txt\")\n",
    "        \n",
    "        print(f\"Modèle : {model_name}\")\n",
    "        print(f\"Accuracy : {accuracy}\")\n",
    "        print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add75fcc",
   "metadata": {},
   "source": [
    "## Évaluation des Modèles Pré-entraînés\n",
    "Utiliser `mlflow` pour suivre les performances des modèles pré-entraînés suivants : `bert-base-uncased`, `textattack/bert-base-uncased-imdb`, `cardiffnlp/twitter-roberta-base-sentiment`, `finiteautomata/bertweet-base-sentiment-analysis`, `vinai/bertweet-base`, `nlptown/bert-base-multilingual-uncased-sentiment`, et `distilbert-base-uncased`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5800af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des modèles pré-entraînés à évaluer\n",
    "pretrained_models = [\n",
    "    \"bert-base-uncased\",\n",
    "    \"textattack/bert-base-uncased-imdb\",\n",
    "    \"cardiffnlp/twitter-roberta-base-sentiment\",\n",
    "    \"finiteautomata/bertweet-base-sentiment-analysis\",\n",
    "    \"vinai/bertweet-base\",\n",
    "    \"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "    \"distilbert-base-uncased\"\n",
    "]\n",
    "\n",
    "# Évaluer chaque modèle\n",
    "for model_name in pretrained_models:\n",
    "    evaluate_model(model_name, X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ff4693",
   "metadata": {},
   "source": [
    "# MLFLOW : \n",
    "Test du serving :\n",
    "Déployer un modèle avec MLFlow Serving :\n",
    "5001\n",
    "Tester l'API de prédiction via un client HTTP (par exemple, Postman ou requests en Python).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bfdcf3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ccafdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd331668",
   "metadata": {},
   "source": [
    "3. Mise en œuvre d’un pipeline de déploiement continu\n",
    "Objectif : Automatiser le déploiement du modèle via une API avec des tests unitaires.\n",
    "Étapes :\n",
    "\n",
    "    1. Versionner le code avec Git et GitHub :\n",
    "\n",
    "        - Créer un dépôt GitHub pour le projet.\n",
    "        - Organiser le code en dossiers :\n",
    "            - src : Contient le code source du modèle et de l’API.\n",
    "            ├── src/\n",
    "            │   ├── model_training.py\n",
    "            │   ├── api.py\n",
    "            │   ├── tests/\n",
    "            │       ├── test_api.py\n",
    "            │       ├── test_model.py\n",
    "            ├── [requirements.txt](http://_vscodecontentref_/0)\n",
    "            ├── Dockerfile\n",
    "            ├── [README.md](http://_vscodecontentref_/1)\n",
    "\n",
    "    2. Créer une API pour le modèle :\n",
    "        - Utiliser FastAPI ou Flask pour exposer le modèle via une API :\n",
    "            from fastapi import FastAPI\n",
    "            import mlflow.pyfunc\n",
    "\n",
    "            app = FastAPI()\n",
    "            model = mlflow.pyfunc.load_model(\"models:/model_name/Production\")\n",
    "\n",
    "            @app.post(\"/predict/\")\n",
    "            def predict(tweet: str):\n",
    "                prediction = model.predict([tweet])\n",
    "                return {\"prediction\": prediction}\n",
    "\n",
    "    3. Écrire des tests unitaires :\n",
    "        - Utiliser pytest pour tester l'API et le modèle :\n",
    "            def test_prediction():\n",
    "                response = client.post(\"/predict/\", json={\"tweet\": \"This is a test tweet\"})\n",
    "                assert response.status_code == 200\n",
    "                assert \"prediction\" in response.json()\n",
    "\n",
    "    4. Configurer un pipeline CI/CD :\n",
    "        - Utiliser GitHub Actions pour automatiser les tests et le déploiement :\n",
    "        Exemple de fichier .github/workflows/deploy.yml :\n",
    "\n",
    "        name: CI/CD Pipeline\n",
    "\n",
    "        on:\n",
    "        push:\n",
    "            branches:\n",
    "            - main\n",
    "\n",
    "        jobs:\n",
    "        test:\n",
    "            runs-on: ubuntu-latest\n",
    "            steps:\n",
    "            - uses: actions/checkout@v3\n",
    "            - name: Set up Python\n",
    "                uses: actions/setup-python@v3\n",
    "                with:\n",
    "                python-version: 3.8\n",
    "            - name: Install dependencies\n",
    "                run: pip install -r requirements.txt\n",
    "            - name: Run tests\n",
    "                run: pytest\n",
    "\n",
    "        deploy:\n",
    "            runs-on: ubuntu-latest\n",
    "            needs: test\n",
    "            steps:\n",
    "            - uses: actions/checkout@v3\n",
    "            - name: Deploy to Azure\n",
    "                run: az webapp up --name <app_name> --resource-group <resource_group> --runtime \"PYTHON:3.8\"\n",
    "\n",
    "    5. Déployer sur une plateforme Cloud gratuite :\n",
    "        - Utiliser Azure Web App (ASP F1 gratuit) :\n",
    "        az webapp up --name <app_name> --resource-group <resource_group> --runtime \"PYTHON:3.8\"\n",
    "\n",
    "        - Alternatives : Heroku, PythonAnywhere, etc.\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd32e422",
   "metadata": {},
   "source": [
    "4.  Suivi de la performance en production avec Azure Application Insights\n",
    "\n",
    "- Objectif : Mettre en place un suivi des prédictions et des alertes.\n",
    "- Étapes :\n",
    "    1. Configurer Application Insights :\n",
    "        - Créer un service Application Insights sur Azure.\n",
    "        - Ajouter le SDK Python dans le projet :\n",
    "\n",
    "            pip install opencensus-ext-azure\n",
    "        - Configurer le traçage dans l'API :\n",
    "\n",
    "        from opencensus.ext.azure.log_exporter import AzureLogHandler\n",
    "        import logging\n",
    "\n",
    "        logger = logging.getLogger(__name__)\n",
    "        logger.addHandler(AzureLogHandler(connection_string=\"InstrumentationKey=<your_instrumentation_key>\"))\n",
    "\n",
    "        @app.post(\"/predict/\")\n",
    "        def predict(tweet: str):\n",
    "            prediction = model.predict([tweet])\n",
    "            if prediction_is_wrong(tweet, prediction):\n",
    "                logger.warning(f\"Misclassified tweet: {tweet}, Prediction: {prediction}\")\n",
    "            return {\"prediction\": prediction}\n",
    "\n",
    "    2. Déclencher des alertes :\n",
    "        - Configurer une alerte dans Application Insights pour détecter un nombre élevé de prédictions incorrectes :\n",
    "        - Exemple : Déclencher une alerte si plus de 3 erreurs en 5 minutes.\n",
    "\n",
    "    3. Analyser les statistiques :\n",
    "        - Utiliser les logs d'Application Insights pour identifier les tweets mal prédits.\n",
    "        - Mettre en place un processus d'amélioration continue :\n",
    "            - Collecter les tweets mal prédits.\n",
    "            - Réentraîner le modèle avec ces données.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682eaf7b",
   "metadata": {},
   "source": [
    "Pour récupérer les credentials azure:\n",
    "installer azure cli https://learn.microsoft.com/en-us/cli/azure/install-azure-cli-windows?tabs=azure-cli\n",
    "sur vscode ouvrir un terminal et taper az login\n",
    "az ad sp create-for-rbac --name \"github-deployment-sp\" --role contributor --scopes /subscriptions/YOUR_SUBSCRIPTION_ID/resourceGroups/YOUR_RESOURCE_GROUP --sdk-auth\n",
    "Le résultat devrait ressembler à ça\n",
    "{\n",
    "  \"clientId\": \"your-client-id\",\n",
    "  \"clientSecret\": \"your-client-secret\",\n",
    "  \"subscriptionId\": \"your-subscription-id\",\n",
    "  \"tenantId\": \"your-tenant-id\",\n",
    "  \"activeDirectoryEndpointUrl\": \"https://login.microsoftonline.com/\",\n",
    "  \"resourceManagerEndpointUrl\": \"https://management.azure.com/\",\n",
    "  \"activeDirectoryGraphResourceId\": \"https://graph.windows.net/\",\n",
    "  \"sqlManagementEndpointUrl\": \"https://management.core.windows.net:8443/\",\n",
    "  \"galleryEndpointUrl\": \"https://gallery.azure.com/\",\n",
    "  \"managementEndpointUrl\": \"https://management.core.windows.net/\"\n",
    "}\n",
    "AZURE_CREDENTIALS: The JSON output from the Service Principal creation.\n",
    "AZURE_RESOURCE_GROUP: The name of your Azure resource group.\n",
    "AZURE_WEBAPP_NAME (if deploying to App Service): The name of your App Service.\n",
    "AZURE_REGION (if deploying to App Service): The region of your App Service.\n",
    "AZURE_CONTAINER_REGISTRY (if using ACR): The name of your container registry.\n",
    "AZURE_REGISTRY_LOGIN_SERVER (if using ACR): The login server URL of your container registry.\n",
    "AZURE_REGISTRY_USERNAME and AZURE_REGISTRY_PASSWORD (if using ACR): The credentials for your ACR.\n",
    "Install the Azure CLI for Windows\n",
    "To install the Azure CLI on Windows, you must use PowerShell, or an MSI installer, which gives you access to the CLI through the Windows Command Prompt (CMD).\n",
    "Install the Azure CLI for Windows\n",
    "créer le compte azure\n",
    "créer un azure container registry puis éxécuter ce qui suit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12974dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Azure for Students"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
