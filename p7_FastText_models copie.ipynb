{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTEXTE \n",
    "\n",
    "Vous êtes ingénieur IA chez MIC (Marketing Intelligence Consulting), une entreprise de conseil spécialisée sur les problématiques de marketing digital.\n",
    "\n",
    "Dans deux semaines, vous avez rendez-vous avec Mme Aline, directrice marketing de la compagnie aérienne “Air Paradis”.\n",
    "\n",
    " \n",
    "\n",
    "Air Paradis a missionné votre cabinet pour créer un produit IA permettant d’anticiper les bad buzz sur les réseaux sociaux. Il est vrai que “Air Paradis” n’a pas toujours bonne presse sur les réseaux…\n",
    "\n",
    "En sortant d’un rendez-vous de cadrage avec les équipes de Air Paradis, vous avez noté les éléments suivants :\n",
    "\n",
    "Air Paradis veut un prototype d’un produit IA permettant de prédire le sentiment associé à un tweet.\n",
    "Données : pas de données clients chez Air Paradis. Solution : utiliser des données Open Source (ou en téléchargement direct à ce lien)\n",
    "Description des données : des informations sur les tweets (utilisateur ayant posté, contenu, moment du post) et un label binaire (tweet exprimant un sentiment négatif ou non). \n",
    "\n",
    "TO-DO :\n",
    "- Préparer un prototype fonctionnel du modèle. Le modèle est exposé via une API déployée sur le Cloud, appelée par une interface locale (notebook ou application Streamlit) qui envoie un tweet à l’API et récupère la prédiction de sentiment. \n",
    "- Préparer un support de présentation explicitant les méthodologies utilisées pour les différentes approches (attention : audience non technique).\n",
    "Après avoir reçu votre compte-rendu, Marc, votre manager, vous a contacté pour, selon ses mots, “faire d’une pierre deux coups”.\n",
    "\n",
    "\n",
    "De : Marc\n",
    "\n",
    "Envoyé : hier 17:14\n",
    "\n",
    "À : vous \n",
    "\n",
    "Objet : Air Paradis : complément\n",
    "\n",
    "Salut \n",
    "\n",
    "Merci pour ton récap du meeting avec Air Paradis. J’ai l’impression que ça s’est bien passé !\n",
    "\n",
    "Je me disais… Puisque tu vas faire un proto pour ce client, j’ai l’intuition que ce produit pourrait se généraliser à d’autres cas d’usage. \n",
    "\n",
    "Tu voudrais bien en profiter pour tester plusieurs approches ?\n",
    "\n",
    "- approche “Modèle sur mesure simple”, pour développer rapidement un modèle classique (ex : régression logistique) permettant de prédire le sentiment associé à un tweet.\n",
    "- approche “Modèle sur mesure avancé” pour développer un modèle basé sur des réseaux de neurones profonds pour prédire le sentiment associé à un tweet. => C’est ce modèle que tu devras déployer et montrer à Air Paradis.\n",
    "\n",
    "Pour cette 2ème approche, tu penseras bien à essayer au moins deux word embeddings différents et à garder celui qui permet d’obtenir les meilleures performances. En complément, pourrais-tu également regarder l’apport en performance d’un modèle BERT ? Cela nous permettra de voir si nous devons investir dans ce type de modèle.\n",
    "\n",
    "\n",
    "Et en même ce serait top si tu pouvais mettre en oeuvre un bon exemple de démarche orientée MLOps, tu sais c’est la nouvelle priorité de notre directeur !\n",
    "\n",
    "J’aimerais que tu puisses démontrer à l’occasion de l’élaboration de ton prototype tout l’apport du MLOps, afin d’assurer une diffusion aux autres équipes : \n",
    "\n",
    "- d’abord réaliser une présentation synthétique des principes du MLOps et ses apports, \n",
    "- ensuite utiliser l’outil MLFlow, future référence pour notre société, pour assurer la gestion des expérimentations des modèles : tracking et reporting de l’entraînement des modèles, centralisation du stockage des modèles, et test du serving proposé par MLFlow, \n",
    "- mettre en œuvre un pipeline de déploiement continu du modèle que tu auras choisi via une API (Git + Github + plateforme Cloud au choix), qui intègre également des tests unitaires automatisés,\n",
    "- et enfin initier un suivi de la performance du modèle en production. Pour cela tu utiliseras un service Azure Application Insight que tu auras créé pour l‘occasion : \n",
    "    - Pour remonter des traces des tweets qui seraient considérés par l’utilisateur comme mal prédits : le texte du tweet et la prédiction.\n",
    "    - Pour déclencher une alerte (envoi SMS ou mail) dans le cas d’un nombre trop important de tweet mal prédits (par exemple 3 tweets mal prédits en l’espace de 5 minutes).\n",
    "    - Présenter une démarche qui pourrait être mise en oeuvre pour l’analyse de ces statistiques et l’amélioration du modèle dans le temps.\n",
    "\n",
    "Nous souhaitons limiter les coûts de mise en production de ce prototype, donc peux-tu privilégier une solution gratuite Cloud pour le déploiement de l’API de prédiction, par exemple Azure webapp (ASP F1 gratuit), PythonAnywhere, Heroku avec le package “student” de Github ou tout autre solution ?\n",
    "\n",
    "\n",
    "Si le modèle avancé est trop lourd et induit un dépassement des limites de taille des solutions gratuites, tu pourras tester le déploiement avec le modèle classique, ou bien utiliser des techniques de réduction de taille de ton modèle TensorFlow-Keras via une conversion en TensorFlow Lite.\n",
    "\n",
    "\n",
    "Merci d’avance !\n",
    "\n",
    "Marc\n",
    "\n",
    "PS : Ah au fait, tant que tu y es, tu pourras rédiger un petit article pour le blog à partir de ton travail de modélisation et de ta démarche orientée MLOps ?\n",
    "\n",
    "\n",
    "## Livrables\n",
    "  \n",
    "1. **L’API de prédiction du score**, qui expose le “Modèle sur mesure avancé”, **déployée sur un service Cloud** , qui recevra en entrée un tweet et retournera le sentiment associé au tweet prédit par le modèle (lien vers l’API sur le Cloud).\n",
    "2. **L’ensemble des scripts** pour réaliser les trois approches (classique, modèle sur mesure avancé, modèle avancé BERT). \n",
    "    - Ce livrable intégrera la gestion des expérimentations avec l’outil MLFlow (tracking des expérimentations, enregistrement des modèles) \n",
    "3. **Un dossier**, géré via un outil de **versioning** de code contenant :\n",
    "    - Le ou les notebooks des modélisations, intégrant via MLFlow le tracking d’expérimentations et le stockage centralisé des modèles\n",
    "    - Le code permettant de déployer le modèle sous forme d'API\n",
    "    - Pour l’API, un fichier introductif permettant de comprendre l'objectif du projet et le découpage des dossiers, et un fichier listant les packages utilisés seront présents dans le dossier\n",
    "4. **Une interface de test de l’API** (notebook ou application Streamlit), exécutée en local, qui permet la saisie d’un tweet, affiche la prédiction, demande une validation à l’utilisateur de la pertinence de la prédiction, et envoie une trace au service Application Insight en cas de non validation\n",
    "5. **Un article de blog** de 1500 à 2000 mots environ (+ copies écrans) contenant : \n",
    "    - Une présentation synthétique et une comparaison des trois approches (“Modèle sur mesure simple” et “Modèle sur mesure avancé”, “Modèle avancé BERT”)\n",
    "    - La démarche orientée MLOps mise en oeuvre : \n",
    "        * principes MLOps, \n",
    "        * étapes mises en oeuvre : tracking, stockage model, gestion version, tests unitaires, déploiement, \n",
    "        * y compris le suivi de la performance en production : traces et alertes sur Azure Application Insight, ainsi qu’une présentation d’une démarche qui pourrait être mise en oeuvre pour l’analyse de ces statistiques et l’amélioration du modèle dans le temps.\n",
    "6. Un support de **présentation** (type PowerPoint) de votre démarche méthodologique, des résultats des différents modèles élaborés via la mise en oeuvre d’expérimentations MLFlow et de sa visualisation via l’UI (User Interface) de MLFlow, et de la mise en production d’un modèle avancé. Il sera également formalisé : \n",
    "Des copies écran des commits, du dossier Github (+ lien vers ce dossier)de l’exécution des tests unitaires, qui sont les preuves qu’un pipeline de déploiement continu a permis de déployer l’API,\n",
    "Des copies écran du suivi de performance sur Azure Application Insight et du déclenchement d’alerte, qui sont les preuves d’un suivi de la performance du modèle en production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÉDICTION DE SENTIMENT À PARTIR DE TWEET - WORD2VEC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-07 00:13:24.934343: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# mlops\n",
    "import mlflow\n",
    "from mlflow.sklearn import save_model\n",
    "# data & science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "# graphiques\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# system & tools\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "# natural language processing\n",
    "import gensim #fasttext\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Concatenate, Input, LSTM, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import regularizers\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "\n",
    "#import sys\n",
    "#sys.path.insert(0, '/Users/stephanieduhem/Documents/MASTER_AI_ENGINEER/openclassroom/tools')\n",
    "#import functions as fct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl les ressources nécessaires pour la tokenisation\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "# dl les ressources nécessaires pour la lemmatisation\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mlflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir l'URI de suivi de MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "#mlflow.set_tracking_uri(\"http://192.168.1.55:5010/\") #depuis le mac (réseau local de rennes) en accèdant au serveur\n",
    "# mlflow.set_tracking_uri(\"http://192.168.48.65:5010/\") #depuis le serveur \n",
    "print(mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\b\\w*[a-zA-Z]+\\w*\\b|\\b[a-zA-Z]+\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixer la radomseed pour la reproductibilité des résultats\n",
    "# Seed value\n",
    "seed_value= 42\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "print(\"os.environ['PYTHONHASHSEED'] == \", os.environ['PYTHONHASHSEED'])\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# Générer des valeurs aléatoires avec NumPy\n",
    "random_values_1 = np.random.uniform(size=[5])\n",
    "print(\"NumPy Valeurs aléatoires 1:\", random_values_1)\n",
    "\n",
    "# Fixer à nouveau la graine pour NumPy et générer les mêmes valeurs\n",
    "np.random.seed(seed_value)\n",
    "random_values_1_recheck = np.random.uniform(size=[5])\n",
    "print(\"NumPy Valeurs aléatoires 1 (recheck):\", random_values_1_recheck)\n",
    "\n",
    "# Vérifier si les valeurs aléatoires de NumPy sont identiques\n",
    "assert np.array_equal(random_values_1, random_values_1_recheck), \"Les valeurs aléatoires de NumPy ne sont pas identiques\"\n",
    "print(\"Les valeurs aléatoires de NumPy sont identiques, la graine est correctement fixée.\")\n",
    "\n",
    "# Générer des valeurs aléatoires avec random\n",
    "random.seed(seed_value)\n",
    "random_values_2 = [random.uniform(0, 1) for _ in range(5)]\n",
    "print(\"random Valeurs aléatoires 2:\", random_values_2)\n",
    "\n",
    "# Fixer à nouveau la graine pour random et générer les mêmes valeurs\n",
    "random.seed(seed_value)\n",
    "random_values_2_recheck = [random.uniform(0, 1) for _ in range(5)]\n",
    "print(\"random Valeurs aléatoires 2 (recheck):\", random_values_2_recheck)\n",
    "\n",
    "# Vérifier si les valeurs aléatoires de random sont identiques\n",
    "assert random_values_2 == random_values_2_recheck, \"Les valeurs aléatoires de random ne sont pas identiques\"\n",
    "print(\"Les valeurs aléatoires de random sont identiques, la graine est correctement fixée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0 = pd.read_csv(\"tweet_low_text.csv\")\n",
    "data_0.info()\n",
    "display(data_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_0['count_token'] = data_0['text_low'].apply(lambda x : len(x))\n",
    "data_0.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupérer la valeur moyenne des longueurs des textes pour le padding\n",
    "data_0['count_token'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour l'affichage des textes dans l'output\n",
    "def print_formated(text, line_length=115):\n",
    "    \"\"\"\n",
    "    Ajoute des retours à la ligne tous les 120 caractères dans une chaîne de caractères pour en faciliter la lecture dans l'output.\n",
    "    args :\n",
    "    text (str): La chaîne de caractères à formater.\n",
    "    line_length (int): La longueur de chaque ligne avant d'ajouter un retour à la ligne, par défaut 120.\n",
    "    \n",
    "    returns:\n",
    "    print(str): La chaîne de caractères formatée avec des retours à la ligne.\n",
    "    \"\"\"\n",
    "    new_text = '\\n'.join([text[i:i+line_length] for i in range(0, len(text), line_length)])\n",
    "    return print(new_text, \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "* bien que pour l'instant nous ne faisons pas de recherche d'hyperparamètres, nous allons quand même utiliser un ensemble de validation pour améliorer la robustesse de nos résultats:\n",
    "- pour permettre une détection de l'overfitting et voir si nous devons réajuster notre pipeline ou nos données\n",
    "- pour comparer nos différents modèles avec des vectorizer différents, les résultats sur l'ensemble de validation nous donnent une métrique de comparaison supplémentaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = 0.1  #  10% des données pour la validation sur le train\n",
    "test_size=0.2 # 20% des données pour le test sur l'ensemble des données\n",
    "# focntion de division du dataset\n",
    "def split_data(X, y, random_state=seed_value):\n",
    "    \"\"\"\n",
    "    Divise le jeu de données en ensembles d'entraînement, de validation et de test.\n",
    "      \n",
    "    \"\"\"\n",
    "   \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed_value, stratify=y)\n",
    "    \n",
    "    X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=val_size, random_state=seed_value, stratify=y_train) \n",
    "\n",
    "    return X_train_final, y_train_final, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data_0[790000:810000].copy()\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data['text_low']))\n",
    "print(len(data['target']))\n",
    "print(data['target'].value_counts())\n",
    "print(\"Exemple avant préprocess : \\n\") \n",
    "print_formated(str(data['text_low'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correspondance entre les labels et les sentiments\n",
    "target_labels = {0: 'Négatif', 1: 'Positif'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification de la répartition des classes dans chaque ensemble issu de la fonction split_data()\n",
    "def check_class_distribution(y_train, y_val, y_test ):\n",
    "    train_counts = np.unique(y_train, return_counts=True)\n",
    "    test_counts = np.unique(y_test, return_counts=True)\n",
    "    val_counts = np.unique(y_val, return_counts=True)\n",
    "    \n",
    "    total_counts = np.sum([train_counts[1], val_counts[1], test_counts[1] ])\n",
    "\n",
    "    train_total_percentage = (np.sum(train_counts[1]) / total_counts) * 100\n",
    "    val_total_percentage = (np.sum(val_counts[1]) / total_counts) * 100\n",
    "    test_total_percentage = (np.sum(test_counts[1]) / total_counts) * 100\n",
    "\n",
    "    train_percentages = (train_counts[1] / total_counts) * 100\n",
    "    val_percentages = (val_counts[1] / total_counts) * 100\n",
    "    test_percentages = (test_counts[1] / total_counts) * 100\n",
    "\n",
    "    categories = np.concatenate([train_counts[0], val_counts[0], test_counts[0] ])\n",
    "    # category_names = [f'{label}' for label in categories]\n",
    "    category_names = [f'{target_labels[label]}' for label in categories]\n",
    "\n",
    "    data = {\n",
    "        'Catégories': category_names,\n",
    "        'Pourcentage': np.concatenate([train_percentages, val_percentages, test_percentages ]),\n",
    "        'Ensemble': ['Train'] * len(train_counts[0]) + ['Validation'] * len(val_counts[0]) + ['Test'] * len(test_counts[0])\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    palette = {'Train': '#1f77b4', 'Validation': '#2ca02c', 'Test': '#ff7f0e'}\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.barplot(x='Catégories', y='Pourcentage', hue='Ensemble', data=df, palette=palette)\n",
    "    plt.title('Répartition des classes dans les ensembles d\\'entraînement, de validation et de test')\n",
    "    plt.xlabel('Sentiment Positif ou Négatif')\n",
    "    plt.ylabel('Pourcentage du dataset total')\n",
    "    plt.xticks(rotation=45)\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    labels = [\n",
    "        f'Train - {train_total_percentage:.2f}%',\n",
    "        f'Validation - {val_total_percentage:.2f}%',\n",
    "        f'Test - {test_total_percentage:.2f}%'\n",
    "    ]\n",
    "    plt.legend(handles=handles, labels=labels, title='Sous-ensembles totaux')\n",
    "    plt.show()\n",
    "\n",
    "# Vérifier la répartition des classessz obtenues avec la fonction split_data()\n",
    "X = data['text_low']\n",
    "y = data['target']\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, random_state=seed_value)\n",
    "\n",
    "check_class_distribution(y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèlisation avec approche FastText \n",
    "* La principale différence entre Word2Vec et FastText réside dans la manière dont ils représentent les mots et gèrent les mots inconnus ou rares :\n",
    "\n",
    "1. Représentation des mots\n",
    "Word2Vec :\n",
    "\n",
    "Représente chaque mot comme un vecteur unique dans l'espace d'embedding.\n",
    "Chaque mot est traité comme une unité indivisible. Par conséquent, les mots rares ou inconnus (non présents dans le vocabulaire d'entraînement) ne peuvent pas être représentés correctement.\n",
    "Exemple : Les mots \"chat\" et \"chats\" auront des vecteurs distincts, sans lien direct entre eux.\n",
    "FastText :\n",
    "\n",
    "Représente les mots en utilisant des n-grammes de caractères (sous-mots). Par exemple, le mot \"chat\" peut être décomposé en sous-mots comme \"ch\", \"cha\", \"hat\", etc.\n",
    "Cela permet de capturer des relations morphologiques entre les mots. Par exemple, \"chat\" et \"chats\" partageront des n-grammes similaires, ce qui les rendra proches dans l'espace d'embedding.\n",
    "\n",
    "2. Gestion des mots inconnus ou rares\n",
    "Word2Vec :\n",
    "\n",
    "Les mots inconnus ou rares (non vus pendant l'entraînement) ne peuvent pas être représentés, car ils n'ont pas de vecteur associé.\n",
    "Cela peut poser problème dans des contextes où le vocabulaire est vaste ou évolutif.\n",
    "FastText :\n",
    "\n",
    "Grâce à l'utilisation des n-grammes, FastText peut générer des embeddings pour des mots inconnus ou rares en combinant les vecteurs de leurs sous-mots.\n",
    "Cela le rend plus robuste pour traiter des mots rares, des fautes d'orthographe ou des mots composés.\n",
    "\n",
    "3. Performance\n",
    "Word2Vec :\n",
    "\n",
    "Plus rapide à entraîner, car il ne décompose pas les mots en sous-mots.\n",
    "Moins gourmand en mémoire.\n",
    "FastText :\n",
    "\n",
    "Plus lent à entraîner, car il doit gérer les n-grammes.\n",
    "Plus performant pour les langues morphologiquement riches (comme le français) ou pour des tâches où les mots rares ou inconnus sont fréquents.\n",
    "\n",
    "4. Applications\n",
    "Word2Vec : Convient pour des tâches où le vocabulaire est bien défini et stable.\n",
    "FastText : Idéal pour des langues complexes, des corpus avec des mots rares, ou des cas où la robustesse face aux mots inconnus est cruciale.\n",
    "\n",
    "\n",
    "* En résumé, FastText est une amélioration de Word2Vec qui prend en compte la structure interne des mots, ce qui le rend plus flexible et performant dans des contextes variés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistiques sur la longueur des textes / choix de la valeur max_length\n",
    "median_length = int(data['text_low'].str.len().median())\n",
    "mean_lengh = int(data['text_low'].str.len().mean())\n",
    "print(\"Longueur médiane des textes : \", median_length)\n",
    "print(\"Longueur max des textes : \", data['text_low'].str.len().max())\n",
    "print(\"Longueur min des textes : \", data['text_low'].str.len().min())\n",
    "print(\"Longueur moyenne des textes : \", mean_lengh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=[\"model_name\", \"fit_time\", \"accuracy_train\", \"accuracy_test\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taille des vecteurs d'embedding (dimensions des embeddings)\n",
    "ft_size = 300  # Identique à ft_size\n",
    "\n",
    "# Taille de la fenêtre de contexte (nombre de mots avant et après le mot cible)\n",
    "ft_window = 5  # Identique à w2v_window\n",
    "\n",
    "# Nombre minimum d'occurrences d'un mot pour qu'il soit inclus dans le vocabulaire\n",
    "ft_min_count = 1  # Identique à w2v_min_count\n",
    "\n",
    "# Nombre d'itérations (ou époques) pour l'entraînement\n",
    "ft_epochs = 100  # Identique à w2v_epochs\n",
    "\n",
    "# Nombre de threads à utiliser pour l'entraînement\n",
    "ft_workers = 8  # pour le multi-threading sur le serveur\n",
    "\n",
    "# Longueur minimale et maximale des n-grammes\n",
    "ft_min_n = 3\n",
    "ft_max_n = 6\n",
    "\n",
    "# Taille de l'espace de hachage pour les n-grammes\n",
    "ft_bucket = 2000000\n",
    "\n",
    "# Nettoyage des textes\n",
    "def clean_text(text):\n",
    "    # Supprimer les URLs + les liens spécifique twitter\n",
    "    text = re.sub(r'www\\S+|http\\S+', '', text) # Supprimer les URLs \n",
    "    text = re.sub(r'pic.twitter.com/\\S+', '', text) # Supprimer les liens spécifique twitter\n",
    "    text = re.sub(r\"@\\w+|#\", \"\", text) # Supprimer les mentions\n",
    "    text = re.sub(r'#', '', text) # Supprimer les hashtags\n",
    "    text = re.sub(r'[^A-Za-z ]+', ' ', text) # Supprimer les caractères non alphabétiquess\n",
    "    text = re.sub(r'\\s+', ' ', text) # Supprimer les espaces multiples\n",
    "    return text\n",
    "\n",
    "\n",
    "# Fonction pour récupérer le type de mot compatible avec WordNet pour un token donné.\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Retourne le type de mot (part of speech) compatible avec WordNet pour un mot donné.\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "# Fonction pour lemmatiser les tokens\n",
    "def lemmatize_tokens(tokens):\n",
    "    \"\"\"\n",
    "    Applique la lemmatisation à une liste de tokens.\n",
    "    \n",
    "    Args:\n",
    "    tokens (list): Liste de tokens à lemmatiser.\n",
    "    \n",
    "    Returns:\n",
    "    set: Ensemble de lemmes.\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = {lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in tokens}\n",
    "    return lemmatized_tokens\n",
    "\n",
    "# Fonction de cleaning et de lemmatisation\n",
    "def clean_and_lemmatize(text):\n",
    "    \"\"\"\n",
    "    Nettoie et lemmatise un texte donné.\n",
    "    \n",
    "    Args:\n",
    "    text (str): Le texte à nettoyer et lemmatiser.\n",
    "    \n",
    "    Returns:\n",
    "    set: Ensemble de tokens lemmatisés.\n",
    "    \"\"\"\n",
    "    # Nettoyer le texte\n",
    "    text = clean_text(text)\n",
    "    # Tokeniser le texte\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    # Lemmatiser les tokens\n",
    "    lemmatized_tokens = lemmatize_tokens(tokens)\n",
    "    return ' '.join(lemmatized_tokens)  # Convertir le set en chaîne de caractères\n",
    "\n",
    "\n",
    "# Fonction de stemming\n",
    "def stem_tokens(tokens):\n",
    "    \"\"\"\n",
    "    Applique le stemming à un texte donné.\n",
    "    \n",
    "    Args:\n",
    "    text (str): Le texte à stemmer.\n",
    "   \n",
    "    Returns:\n",
    "    str: Le texte stemmé.\n",
    "    \"\"\"\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_tokens = {stemmer.stem(token) for token in tokens}\n",
    "    return stemmed_tokens\n",
    "\n",
    "# Fonction de nettoyage et de stemming\n",
    "def clean_and_stem(text):\n",
    "    \"\"\"\n",
    "    Nettoie et stemme un texte donné.\n",
    "    \n",
    "    Args:\n",
    "    text (str): Le texte à nettoyer et stemmer.\n",
    "    \n",
    "    Returns:\n",
    "    set: Ensemble de tokens stemmés.\n",
    "    \"\"\"\n",
    "    # Nettoyer le texte\n",
    "    text = clean_text(text)\n",
    "    # Tokeniser le texte\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    # Stemming\n",
    "    stemmed_tokens = stem_tokens(tokens)\n",
    "    return ' '.join(stemmed_tokens)  # Convertir le set en chaîne de caractère\n",
    "\n",
    "# Builder le vocabulaire et entraîner le modèle Word2Vec\n",
    "def build_and_train_fastext_model(X_train, seed=seed_value):\n",
    "     # Initialiser et entraîner le modèle FastText\n",
    "    ft_model = gensim.models.FastText(\n",
    "    vector_size=ft_size,\n",
    "    window=ft_window,\n",
    "    min_count=ft_min_count,\n",
    "    epochs=ft_epochs,\n",
    "    seed=seed_value,\n",
    "    workers=ft_workers,\n",
    "    min_n=ft_min_n,\n",
    "    max_n=ft_max_n,\n",
    "    bucket=ft_bucket)\n",
    "    ft_model.build_vocab(X_train)\n",
    "    ft_model.train(X_train, total_examples=ft_model.corpus_count, epochs=ft_epochs)\n",
    "\n",
    "    model_vectors = ft_model.wv\n",
    "    ft_words = model_vectors.index_to_key\n",
    "    # print(\"Nombre de mots présents dans le vocabulaire : %i\" % len(ft_words))\n",
    "    return ft_model, ft_words\n",
    "\n",
    "#transformer les listes de tokens en vecteurs\n",
    "def transform_to_vectors(sentences, ft_model):\n",
    "    vectors = []\n",
    "    for sentence in sentences:\n",
    "        word_vectors = [ft_model.wv[word] for word in sentence if word in ft_model.wv]\n",
    "        if word_vectors:\n",
    "            vectors.append(np.mean(word_vectors, axis=0))\n",
    "        else:\n",
    "            vectors.append(np.zeros(ft_model.vector_size))\n",
    "    return np.array(vectors)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fonction pour créer un modèle CNN\n",
    "def create_cnn_model(vocab_size, embedding_matrix, embedding_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, weights=[embedding_matrix], trainable=False))  # Suppression de input_length\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Fonction pour créer un modèle TextCNN\n",
    "def create_textcnn_model(vocab_size, embedding_matrix, embedding_size, input_length):\n",
    "    input_layer = Input(shape=(input_length,))  # Spécifiez la longueur d'entrée\n",
    "    embedding_layer = Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_size,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=input_length,  # Ajoutez input_length ici\n",
    "        trainable=False\n",
    "    )(input_layer)\n",
    "    \n",
    "    convs = []\n",
    "    filter_sizes = [3, 4, 5]\n",
    "    for filter_size in filter_sizes:\n",
    "        conv = Conv1D(filters=128, kernel_size=filter_size, activation='relu')(embedding_layer)\n",
    "        pool = MaxPooling1D(pool_size=2)(conv)\n",
    "        flat = Flatten()(pool)\n",
    "        convs.append(flat)\n",
    "    \n",
    "    merged = Concatenate()(convs)\n",
    "    dense = Dense(128, activation='relu')(merged)\n",
    "    output_layer = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Fonction pour créer un modèle RNN\n",
    "def create_rnn_model(vocab_size, embedding_matrix, embedding_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, weights=[embedding_matrix], input_length=100, trainable=False)) \n",
    "    model.add(LSTM(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.3))\n",
    "    model.add(LSTM(128, return_sequences=False, dropout=0.3, recurrent_dropout=0.3))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# LTSM bidirectionnel à voir, papers with code (références dataset avec derniers articles)\n",
    "def create_bilstm_model(vocab_size, embedding_matrix, embedding_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, weights=[embedding_matrix], trainable=False)) \n",
    "    model.add(Bidirectional(LSTM(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)))\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrapper personnalisé pour KerasClassifier\n",
    "class KerasClassifierWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, build_fn, embedding_matrix, embedding_size, **kwargs):\n",
    "        self.build_fn = build_fn\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.embedding_size = embedding_size\n",
    "        self.kwargs = kwargs\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        self.model = self.build_fn(embedding_matrix=self.embedding_matrix, embedding_size=self.embedding_size, **self.kwargs)\n",
    "        self.model.fit(X, y, **fit_params)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.model.predict(X) > 0.5).astype(\"int32\")\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "\n",
    "# Fonction pour entraîner et évaluer le modèle\n",
    "def train_and_evaluate_model_ft(results_df, reduction, classifier_name, embedding_size=ft_size, **fit_params):\n",
    "    if mlflow.active_run() is not None:\n",
    "        mlflow.end_run()\n",
    "\n",
    "    # Définir le nom du modèle\n",
    "    model_name = f\"ft_{reduction}_{classifier_name}\"\n",
    "    print(\"Nom du modèle:\", model_name)\n",
    "      \n",
    "    # Preprocessing des données : vectorisation et nettoyage puis split en train, val et test   \n",
    "    print(\"Début du préprocessing des données\")\n",
    "    start_time = time.time()\n",
    "    # nettoyage et vectorisation\n",
    "    if reduction == \"stem\":\n",
    "        data['clean_reduct_text'] = data['text_low'].apply(clean_and_stem)\n",
    "  \n",
    "    elif reduction == \"lem\":\n",
    "        data['clean_reduct_text'] = data['text_low'].apply(clean_and_lemmatize)\n",
    "        \n",
    "    # print(type(data['clean_reduct_text'].iloc[0]))\n",
    "    print(\"Exemple après préprocess (\", reduction, \") : \\n\") \n",
    "    print_formated(data['clean_reduct_text'].iloc[0])\n",
    "    \n",
    "    data['sentences'] = [gensim.utils.simple_preprocess(text) for text in data['clean_reduct_text'].to_list()]\n",
    "    \n",
    "    # séparer les données en ensemble de train, de validation et de test\n",
    "    X = data['sentences']\n",
    "    y = data['target']\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, random_state=seed_value)\n",
    "    \n",
    "    ft_model, ft_words = build_and_train_fastext_model(X_train, seed=seed_value)\n",
    "    embedding_matrix=ft_model.wv.vectors\n",
    "    \n",
    "    X_train_vectors = transform_to_vectors(X_train, ft_model)\n",
    "    X_val_vectors = transform_to_vectors(X_val, ft_model)\n",
    "    X_test_vectors = transform_to_vectors(X_test, ft_model)\n",
    "\n",
    "    # Créer un exemple d'entrée basé sur les données d'entraînement\n",
    "    input_example = pd.DataFrame([X_train_vectors[0]])\n",
    "\n",
    "    preprocessing_time = time.time() - start_time   \n",
    "    print(\"Fin du préprocessing des données - Durée:\", preprocessing_time, \"secondes\")\n",
    "    \n",
    "    # Init le modèle\n",
    "    if classifier_name == \"Reg_Log\":\n",
    "        classifier = LogisticRegression(penalty='l2', C=1.0, random_state=seed_value, max_iter=1000)\n",
    "    elif classifier_name == \"CNN\":\n",
    "        classifier = KerasClassifierWrapper(\n",
    "            build_fn=create_cnn_model,\n",
    "            #input_length=len(X_train_vectors[0]),\n",
    "            vocab_size=len(ft_words),  \n",
    "            embedding_matrix=ft_model.wv.vectors,  \n",
    "            embedding_size=ft_size)\n",
    "    elif classifier_name == \"TextCNN\":\n",
    "        classifier = KerasClassifierWrapper(\n",
    "            build_fn=create_textcnn_model,\n",
    "            input_length=len(X_train_vectors[0]),\n",
    "            vocab_size=len(ft_words),  \n",
    "            embedding_matrix=ft_model.wv.vectors,  \n",
    "            embedding_size=ft_size)\n",
    "    elif classifier_name == \"RNN\":\n",
    "        classifier = KerasClassifierWrapper(\n",
    "            build_fn=create_rnn_model,\n",
    "            #input_length=len(X_train_vectors[0]),\n",
    "            vocab_size=len(ft_words),  \n",
    "            embedding_matrix=ft_model.wv.vectors,  \n",
    "            embedding_size=ft_size)\n",
    "    elif classifier_name == \"BiLSTM\":\n",
    "        classifier = KerasClassifierWrapper(\n",
    "            build_fn=create_bilstm_model,\n",
    "            #input_length=len(X_train_vectors[0]),\n",
    "            vocab_size=len(ft_words),\n",
    "            embedding_matrix=ft_model.wv.vectors, \n",
    "            embedding_size=ft_size)      \n",
    "    \n",
    "    print(f\"Modèle créé {classifier_name} - ok\")\n",
    "    \n",
    "    # Démarrer une nouvelle exécution MLflow\n",
    "    with mlflow.start_run(run_name=model_name) as run:\n",
    "        # Enregistrer les hyperparamètres\n",
    "        mlflow.log_param(\"classifier\", classifier_name)\n",
    "        mlflow.log_param(\"embedding_size\", embedding_size)\n",
    "        # Ajouter une balise avec le nom du modèle\n",
    "        mlflow.set_tag(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"test_size\", test_size)\n",
    "        mlflow.log_param(\"val_size\", val_size)\n",
    "        # Enregistrer des informations sur la matrice d'embedding\n",
    "        mlflow.log_param(\"embedding_matrix_shape\", embedding_matrix.shape)\n",
    "        \n",
    "        # Entraîner le modèle\n",
    "        print(\"Entraînement du modèle\")\n",
    "        start_time = time.time()\n",
    "        classifier.fit(X_train_vectors, y_train, **fit_params)\n",
    "        fit_time = time.time() - start_time\n",
    "        print(\"Modèle entraîné - durée:\", fit_time, \"secondes\")\n",
    "        \n",
    "        # Prédire et évaluer le modèle sur le train\n",
    "        start_time = time.time()\n",
    "        y_pred_train = classifier.predict(X_train_vectors)\n",
    "        train_predict_time = time.time() - start_time\n",
    "        print(\"Prédictions sur le train - durée:\", train_predict_time, \"secondes\")\n",
    "        accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "        auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "        \n",
    "        \n",
    "        # Prédire et évaluer le modèle sur la valitation\n",
    "        start_time = time.time()\n",
    "        y_pred_val = classifier.predict(X_val_vectors)\n",
    "        val_predict_time = time.time() - start_time\n",
    "        print(\"Prédictions sur la validation - durée:\", val_predict_time, \"secondes\")\n",
    "        accuracy_val = accuracy_score(y_train, y_pred_train)\n",
    "        auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "       \n",
    "\n",
    "        # Prédire et évaluer le modèle sur le test\n",
    "        start_time = time.time()\n",
    "        y_pred_test = classifier.predict(X_test_vectors)\n",
    "        test_predict_time = time.time() - start_time\n",
    "        print(\"Prédictions sur le test - durée:\", test_predict_time, \"secondes\")\n",
    "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "        auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "        \n",
    "        # Enregistrer les métriques\n",
    "        mlflow.log_metric(\"accuracy_test\", accuracy_test)\n",
    "        mlflow.log_metric(\"auc_test\", auc_test)\n",
    "        mlflow.log_metric(\"accuracy_train\", accuracy_train)\n",
    "        mlflow.log_metric(\"auc_train\", auc_train)\n",
    "        mlflow.log_metric(\"accuracy_val\", accuracy_val)\n",
    "        mlflow.log_metric(\"auc_val\", auc_val)\n",
    "        mlflow.log_metric(\"fit_time\", fit_time)\n",
    "        mlflow.log_metric(\"train_predict_time\", train_predict_time)\n",
    "        mlflow.log_metric(\"val_predict_time\", val_predict_time)\n",
    "        mlflow.log_metric(\"test_predict_time\", test_predict_time)\n",
    "        mlflow.log_metric(\"preprocessing_time\", preprocessing_time)\n",
    "\n",
    "        # Enregistrer le modèle avec un nom personnalisé et un exemple d'entrée\n",
    "        model_info = mlflow.sklearn.log_model(classifier, model_name, input_example=input_example)\n",
    "        model_uri = model_info.model_uri\n",
    "        mlflow.register_model(model_uri, model_name)\n",
    "        # Enregistrer le modèle dans un répertoire local avec mlflow.sklearn.save_model\n",
    "        save_model(classifier, path=f\"artifacts/{model_name}\")\n",
    "        \n",
    "        print(\"Modèle enregistré - ok\")\n",
    "        \n",
    "        # Visualisation des résultats\n",
    "        print(\"Affichage des métriques d'évaluation\")\n",
    "        print(\"Rapport de classification sur le train: \\n\", classification_report(y_train, y_pred_train))\n",
    "        print(\"Rapport de classification sur la validation: \\n\", classification_report(y_val, y_pred_val))\n",
    "        print(\"Rapport de classification sur le test: \\n\", classification_report(y_test, y_pred_test))\n",
    "    \n",
    "             \n",
    "        # Générer et enregistrer la courbe ROC\n",
    "        fpr, tpr, _ = roc_curve(y_val, y_pred_val)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc_val)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'Validation - ROC Curve for {model_name}')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(f\"./Graph_eval/Roc_curve/roc_curve_{model_name}.png\")\n",
    "        mlflow.log_artifact(f\"./Graph_eval/Roc_curve/roc_curve_{model_name}.png\")\n",
    "        \n",
    "        # Générer et enregistrer la courbe ROC\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_test)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc_test)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'Test - ROC Curve for {model_name}')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(f\"./Graph_eval/Roc_curve/roc_curve_{model_name}.png\")\n",
    "        mlflow.log_artifact(f\"./Graph_eval/Roc_curve/roc_curve_{model_name}.png\")\n",
    "        \n",
    "       # Générer et enregistrer la matrice de confusion pour le train\n",
    "        cm_train = confusion_matrix(y_train, y_pred_train)\n",
    "        cm_percent_train = cm_train.astype('float') / cm_train.sum(axis=1)[:, np.newaxis] * 100\n",
    "        cm_display_train = np.array([[\"{0:.0f}\\n({1:.1f}%)\".format(value, percent) for value, percent in zip(row, row_percent)] for row, row_percent in zip(cm_train, cm_percent_train)])\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm_train, annot=cm_display_train, fmt='', cmap='Blues', xticklabels=[target_labels[0], target_labels[1]], yticklabels=[target_labels[0], target_labels[1]])\n",
    "        plt.xlabel('Prédit')\n",
    "        plt.ylabel('Réel')\n",
    "        plt.title(f'Matrice de Confusion {model_name} (Train)')\n",
    "        plt.savefig(f\"./Graph_eval/Conf_Mat_Train/confusion_matrix_{model_name}_train.png\")\n",
    "        mlflow.log_artifact(f\"./Graph_eval/Conf_Mat_Train/confusion_matrix_{model_name}_train.png\")\n",
    "        \n",
    "        # Générer et enregistrer la matrice de confusion pour le train\n",
    "        cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "        cm_percent_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis] * 100\n",
    "        cm_display_val = np.array([[\"{0:.0f}\\n({1:.1f}%)\".format(value, percent) for value, percent in zip(row, row_percent)] for row, row_percent in zip(cm_val, cm_percent_val)])\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm_val, annot=cm_display_val, fmt='', cmap='Greens', xticklabels=[target_labels[0], target_labels[1]], yticklabels=[target_labels[0], target_labels[1]])\n",
    "        plt.xlabel('Prédit')\n",
    "        plt.ylabel('Réel')\n",
    "        plt.title(f'Matrice de Confusion {model_name} (Validation)')\n",
    "        plt.savefig(f\"./Graph_eval/Conf_Mat_val/confusion_matrix_{model_name}_val.png\")\n",
    "        mlflow.log_artifact(f\"./Graph_eval/Conf_Mat_val/confusion_matrix_{model_name}_val.png\")\n",
    "        \n",
    "        # Générer et enregistrer la matrice de confusion pour le test\n",
    "        cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "        cm_percent_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis] * 100\n",
    "        cm_display_test = np.array([[\"{0:.0f}\\n({1:.1f}%)\".format(value, percent) for value, percent in zip(row, row_percent)] for row, row_percent in zip(cm_test, cm_percent_test)])\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm_test, annot=cm_display_test, fmt='', cmap='YlOrBr', xticklabels=[target_labels[0], target_labels[1]], yticklabels=[target_labels[0], target_labels[1]])\n",
    "        plt.xlabel('Prédit')\n",
    "        plt.ylabel('Réel')\n",
    "        plt.title(f'Matrice de Confusion {model_name} (Test)')\n",
    "        plt.savefig(f\"./Graph_eval/Conf_Mat_Test/confusion_matrix_{model_name}_test.png\")\n",
    "        mlflow.log_artifact(f\"./Graph_eval/Conf_Mat_Test/confusion_matrix_{model_name}_test.png\")\n",
    "\n",
    "        # Afficher le run_id\n",
    "        run_id = run.info.run_id\n",
    "        print(f\"Run ID ({model_name}): {run_id}\")\n",
    "        \n",
    "        # Synthèse des résultats\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([{\"model_name\": model_name, \"fit_time\": fit_time, \"accuracy_train\": accuracy_train, \"accuracy_test\": accuracy_test}])], ignore_index=True)\n",
    "    \n",
    "    return results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests de Modèles de Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Régression Logistique avec Stemming en pré-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model_ft(results_df, \"stem\", \"Reg_Log\", embedding_size=ft_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Régression Logistique avec Lemmatisation en pré-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model_ft(results_df, \"lem\", \"Reg_Log\", embedding_size=ft_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test CNN classifier avec Stemming en pré-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model_ft(results_df, \"stem\", \"CNN\", embedding_size=ft_size, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test CNN classifier avec Lemmatisation en pré-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model_ft(results_df, \"lem\", \"CNN\", embedding_size=ft_size, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test TextCNN classifier avec Stemming en pré-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model_ft(results_df, \"stem\", \"TextCNN\", embedding_size=ft_size, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test TextCNN classifier avec Lemmatisation en pré-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model_ft(results_df, \"lem\", \"TextCNN\", embedding_size=ft_size, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test RNN classifier avec Stemming en pré-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model_ft(results_df, \"stem\", \"RNN\", embedding_size=ft_size, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test RNN classifier avec Lemmatisation en pré-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model_ft(results_df, \"lem\", \"RNN\", embedding_size=ft_size, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test BiLSTM classifier avec Stemming en pré-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model_ft(results_df, \"stem\", \"BiLSTM\", embedding_size=ft_size, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test BiLSTM classifier avec Lematisation en pré-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model_ft(results_df, \"lem\", \"BiLSTM\", embedding_size=ft_size, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthèse des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fonction pour créer un modèle CNN\n",
    "def create_cnn_model(vocab_size, embedding_matrix, embedding_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, weights=[embedding_matrix], trainable=False))  # Suppression de input_length\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# # Fonction pour créer un modèle TextCNN\n",
    "# def create_textcnn_model(vocab_size, embedding_matrix, embedding_size):\n",
    "#     input_layer = Input(shape=(None,))  # Remplacement de input_length par None\n",
    "#     embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_size, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    \n",
    "#     convs = []\n",
    "#     filter_sizes = [3, 4, 5]\n",
    "#     for filter_size in filter_sizes:\n",
    "#         conv = Conv1D(filters=128, kernel_size=filter_size, activation='relu')(embedding_layer)\n",
    "#         pool = MaxPooling1D(pool_size=2)(conv)\n",
    "#         flat = Flatten()(pool)\n",
    "#         convs.append(flat)\n",
    "    \n",
    "#     merged = Concatenate()(convs)\n",
    "#     dense = Dense(128, activation='relu')(merged)\n",
    "#     output_layer = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "#     model = Model(inputs=input_layer, outputs=output_layer)\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "def create_textcnn_model(vocab_size, embedding_matrix, embedding_size, input_length):\n",
    "    input_layer = Input(shape=(input_length,))  # Spécifiez la longueur d'entrée\n",
    "    embedding_layer = Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_size,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=input_length,  # Ajoutez input_length ici\n",
    "        trainable=False\n",
    "    )(input_layer)\n",
    "    \n",
    "    convs = []\n",
    "    filter_sizes = [3, 4, 5]\n",
    "    for filter_size in filter_sizes:\n",
    "        conv = Conv1D(filters=128, kernel_size=filter_size, activation='relu')(embedding_layer)\n",
    "        pool = MaxPooling1D(pool_size=2)(conv)\n",
    "        flat = Flatten()(pool)\n",
    "        convs.append(flat)\n",
    "    \n",
    "    merged = Concatenate()(convs)\n",
    "    dense = Dense(128, activation='relu')(merged)\n",
    "    output_layer = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Fonction pour créer un modèle RNN\n",
    "def create_rnn_model(vocab_size, embedding_matrix, embedding_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, weights=[embedding_matrix], input_length=100, trainable=False)) \n",
    "    model.add(LSTM(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.3))\n",
    "    model.add(LSTM(128, return_sequences=False, dropout=0.3, recurrent_dropout=0.3))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# LTSM bidirectionnel à voir, papers with code (références dataset avec derniers articles)\n",
    "def create_bilstm_model(vocab_size, embedding_matrix, embedding_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, weights=[embedding_matrix], trainable=False)) \n",
    "    model.add(Bidirectional(LSTM(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)))\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=False, dropout=0.3, recurrent_dropout=0.3)))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrapper personnalisé pour KerasClassifier\n",
    "class KerasClassifierWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, build_fn, embedding_matrix, embedding_size, **kwargs):\n",
    "        self.build_fn = build_fn\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.embedding_size = embedding_size\n",
    "        self.kwargs = kwargs\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        self.model = self.build_fn(embedding_matrix=self.embedding_matrix, embedding_size=self.embedding_size, **self.kwargs)\n",
    "        self.model.fit(X, y, **fit_params)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return (self.model.predict(X) > 0.5).astype(\"int32\")\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "\n",
    "# Fonction pour entraîner et évaluer le modèle\n",
    "def train_and_evaluate_model(classifier, classifier_name, embedding_matrix, embedding_size, **fit_params):\n",
    "    if mlflow.active_run() is not None:\n",
    "        mlflow.end_run()\n",
    "\n",
    "    # Créer un pipeline avec le scaler et le classifieur\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler(with_mean=False)),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "\n",
    "    # Créer un exemple d'entrée basé sur les données d'entraînement\n",
    "    input_example = pd.DataFrame([X_train_vectors[0]])\n",
    "    \n",
    "    # Définir le nom du modèle\n",
    "    model_name = f\"{classifier_name}\"\n",
    "    \n",
    "    # Démarrer une nouvelle exécution MLflow\n",
    "    with mlflow.start_run(run_name=model_name) as run:\n",
    "        # Enregistrer les hyperparamètres\n",
    "        mlflow.log_param(\"classifier\", classifier_name)\n",
    "        mlflow.log_param(\"embedding_size\", embedding_size)\n",
    "        # Ajouter une balise avec le nom du modèle\n",
    "        mlflow.set_tag(\"model_name\", model_name)\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        # Enregistrer le nom du dataset \n",
    "        mlflow.set_tag(\"Dataset\", dataset_name)\n",
    "        mlflow.log_param(\"dataset_name\", dataset_name)\n",
    "        mlflow.log_artifact(dataset_name, artifact_path=\"datasets\")\n",
    "        # Enregistrer des informations sur la matrice d'embedding\n",
    "        mlflow.log_param(\"embedding_matrix_shape\", embedding_matrix.shape)\n",
    "\n",
    "        # Entraîner le modèle\n",
    "        start_time = time.time()\n",
    "        pipeline.fit(X_train_vectors, y_train, **{f'classifier__{k}': v for k, v in fit_params.items()})\n",
    "        fit_time = time.time() - start_time\n",
    "        # Prédire et évaluer le modèle sur l'ensemble d'entraînement\n",
    "        y_pred_train = pipeline.predict(X_train_vectors)\n",
    "        accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "        auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "\n",
    "        # Prédire et évaluer le modèle sur le test\n",
    "        start_time = time.time()\n",
    "        y_pred_test = pipeline.predict(X_test_vectors)\n",
    "        predict_time = time.time() - start_time\n",
    "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "        auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "        # Enregistrer les métriques\n",
    "        mlflow.log_metric(\"accuracy_test\", accuracy_test)\n",
    "        mlflow.log_metric(\"auc_test\", auc_test)\n",
    "        mlflow.log_metric(\"accuracy_train\", accuracy_train)\n",
    "        mlflow.log_metric(\"auc_train\", auc_train)\n",
    "        mlflow.log_metric(\"fit_time\", fit_time)\n",
    "        mlflow.log_metric(\"predict_time\", predict_time)\n",
    "\n",
    "        # Enregistrer le modèle avec un nom personnalisé et un exemple d'entrée\n",
    "        model_info = mlflow.sklearn.log_model(pipeline, model_name, input_example=input_example)\n",
    "        model_uri = model_info.model_uri\n",
    "        mlflow.register_model(model_uri, model_name)\n",
    "\n",
    "        # Générer et enregistrer la courbe ROC\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_pred_test)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc_test)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'Courbe ROC {model_name}')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(f\"./Graph_eval/Roc_curve/roc_curve_{model_name}.png\")\n",
    "        mlflow.log_artifact(f\"./Graph_eval/Roc_curve/roc_curve_{model_name}.png\")\n",
    "        \n",
    "       # Générer et enregistrer la matrice de confusion pour le train\n",
    "        cm_train = confusion_matrix(y_train, y_pred_train)\n",
    "        cm_percent_train = cm_train.astype('float') / cm_train.sum(axis=1)[:, np.newaxis] * 100\n",
    "        cm_display_train = np.array([[\"{0:.0f}\\n({1:.1f}%)\".format(value, percent) for value, percent in zip(row, row_percent)] for row, row_percent in zip(cm_train, cm_percent_train)])\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm_train, annot=cm_display_train, fmt='', cmap='Blues', xticklabels=[target_labels[0], target_labels[1]], yticklabels=[target_labels[0], target_labels[1]])\n",
    "        plt.xlabel('Prédit')\n",
    "        plt.ylabel('Réel')\n",
    "        plt.title(f'Matrice de Confusion {model_name} (Train)')\n",
    "        plt.savefig(f\"./Graph_eval/Conf_Mat_Train/confusion_matrix_{model_name}_train.png\")\n",
    "        mlflow.log_artifact(f\"./Graph_eval/Conf_Mat_Train/confusion_matrix_{model_name}_train.png\")\n",
    "        \n",
    "        # Générer et enregistrer la matrice de confusion pour le test\n",
    "        cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "        cm_percent_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis] * 100\n",
    "        cm_display_test = np.array([[\"{0:.0f}\\n({1:.1f}%)\".format(value, percent) for value, percent in zip(row, row_percent)] for row, row_percent in zip(cm_test, cm_percent_test)])\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm_test, annot=cm_display_test, fmt='', cmap='YlOrBr', xticklabels=[target_labels[0], target_labels[1]], yticklabels=[target_labels[0], target_labels[1]])\n",
    "        plt.xlabel('Prédit')\n",
    "        plt.ylabel('Réel')\n",
    "        plt.title(f'Matrice de Confusion {model_name} (Test)')\n",
    "        plt.savefig(f\"./Graph_eval/Conf_Mat_Test/confusion_matrix_{model_name}_test.png\")\n",
    "        mlflow.log_artifact(f\"./Graph_eval/Conf_Mat_Test/confusion_matrix_{model_name}_test.png\")\n",
    "\n",
    "        # Afficher le run_id\n",
    "        run_id = run.info.run_id\n",
    "        print(f\"Run ID ({model_name}): {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests de Modèles de Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Régression Logistique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression = LogisticRegression(penalty='l2', C=1.0, random_state=seed_value, max_iter=1000)\n",
    "\n",
    "train_and_evaluate_model(logistic_regression, \"fastxt_LogisticRegression\", embedding_matrix=ft_model.wv.vectors, embedding_size=ft_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test CNN clasifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_classifier = KerasClassifierWrapper(\n",
    "    build_fn=create_cnn_model,\n",
    "    #input_length=len(X_train_vectors[0]),\n",
    "    vocab_size=len(ft_words),  \n",
    "    embedding_matrix=ft_model.wv.vectors,  \n",
    "    embedding_size=ft_size)\n",
    "\n",
    "train_and_evaluate_model(cnn_classifier, \"fastxt_CNN\", embedding_matrix=ft_model.wv.vectors, embedding_size=ft_size, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test TextCNN clasifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textcnn_classifier = KerasClassifierWrapper(\n",
    "    build_fn=create_textcnn_model,\n",
    "    input_length=len(X_train_vectors[0]),\n",
    "    vocab_size=len(ft_words),  \n",
    "    embedding_matrix=ft_model.wv.vectors,  \n",
    "    embedding_size=ft_size)\n",
    "\n",
    "\n",
    "train_and_evaluate_model(textcnn_classifier, \"fastxt_TextCNN\", embedding_matrix=ft_model.wv.vectors, embedding_size=ft_size, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test RNN clasifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_classifier = KerasClassifierWrapper(\n",
    "    build_fn=create_rnn_model,\n",
    "    #input_length=len(X_train_vectors[0]),\n",
    "    vocab_size=len(ft_words),  \n",
    "    embedding_matrix=ft_model.wv.vectors,  \n",
    "    embedding_size=ft_size)\n",
    "\n",
    "train_and_evaluate_model(rnn_classifier, \"fastxt_RNN\", embedding_matrix=ft_model.wv.vectors, embedding_size=ft_size, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test BiLSTM clasifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_classifier = KerasClassifierWrapper(\n",
    "    build_fn=create_bilstm_model,\n",
    "    #input_length=len(X_train_vectors[0]),\n",
    "    vocab_size=len(ft_words),\n",
    "    embedding_matrix=ft_model.wv.vectors, \n",
    "    embedding_size=ft_size)\n",
    "\n",
    "train_and_evaluate_model(bilstm_classifier,\"fastxt_BiLSTM\",embedding_matrix=ft_model.wv.vectors,embedding_size=ft_size, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_p7_chantepie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
